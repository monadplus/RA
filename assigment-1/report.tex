\documentclass[12pt, a4paper]{article} % book, report, article, letter, slides
                                       % letterpaper/a4paper, 10pt/11pt/12pt, twocolumn/twoside/landscape/draft

%%%%%%%%%%%%%%%% PACKAGES %%%%%%%%%%%%%%%%%%%%%

\usepackage[utf8]{inputenc} % encoding

\usepackage[english]{babel} % use special characters and also translates some elements within the document.

\usepackage{amsmath}        % Math
\usepackage{amsthm}         % Math, \newtheorem, \proof, etc
\usepackage{amssymb}        % Math, extended collection
\usepackage{bm}             % $\bm{D + C}$
\newtheorem{theorem}{Theorem}[section]     % \begin{theorem}\label{t:label}  \end{theorem}<Paste>
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newenvironment{claim}[1]{\par\noindent\underline{Claim:}\space#1}{}
\newenvironment{claimproof}[1]{\par\noindent\underline{Proof:}\space#1}{\hfill $\blacksquare$}

\usepackage{hyperref}       % Hyperlinks \url{url} or \href{url}{name}

\usepackage{parskip}        % \par starts on left (not idented)

\usepackage{abstract}       % Abstract

\usepackage{enumitem}       % \item[$ast$] Foo

\usepackage{tocbibind}      % Adds the bibliography to the table of contents (automatically)

\usepackage{graphicx}       % Images
\graphicspath{{./images/}}

\usepackage[vlined,ruled]{algorithm2e} % pseudo-code

% \usepackage[document]{ragged2e}  % Left-aligned (whole document)
% \begin{...} ... \end{...}   flushleft, flushright, center

%%%%%%%%%%%%%%%% CODE %%%%%%%%%%%%%%%%%%%%%

\usepackage{minted}         % Code listing
% \mint{html}|<h2>Something <b>here</b></h2>|
% \inputminted{octave}{BitXorMatrix.m}

%\begin{listing}[H]
  %\begin{minted}[xleftmargin=20pt,linenos,bgcolor=codegray]{haskell}
  %\end{minted}
  %\caption{Example of a listing.}
  %\label{lst:example} % You can reference it by \ref{lst:example}
%\end{listing}

\newcommand{\code}[1]{\texttt{#1}} % Define \code{foo.hs} environment

%%%%%%%%%%%%%%%% COLOURS %%%%%%%%%%%%%%%%%%%%%

\usepackage{xcolor}         % Colours \definecolor, \color{codegray}
\definecolor{codegray}{rgb}{0.9, 0.9, 0.9}
% \color{codegray} ... ...
% \textcolor{red}{easily}

%%%%%%%%%%%%%%%% CONFIG %%%%%%%%%%%%%%%%%%%%%

\renewcommand{\absnamepos}{flushleft}
\setlength{\absleftindent}{0pt}
\setlength{\absrightindent}{0pt}

%%%%%%%%%%%%%%%% GLOSSARIES %%%%%%%%%%%%%%%%%%%%%

%\usepackage{glossaries}

%\makeglossaries % before entries

%\newglossaryentry{latex}{
    %name=latex,
    %description={Is a mark up language specially suited
    %for scientific documents}
%}

% Referene to a glossary \gls{latex}
% Print glossaries \printglossaries

\usepackage[acronym]{glossaries} %

% \acrshort{name}
% \acrfull{name}
\newacronym{kcol}{$k$-COL}{$k$-coloring problem}
\newacronym{scol}{SEARCH-$k$-COL}{Search $k$-coloring problem}
\newacronym{2col}{$2$-COL}{$2$-coloring problem}
\newacronym{e2sat}{$E2$-SAT}{Exactly 2-SAT}

%%%%%%%%%%%%%%%%%%%%%

\usepackage[displaymath,textmath,sections,graphics,floats]{preview}
% \PreviewEnvironment{enumerate}
\PreviewEnvironment{tabular}

%%%%%%%%%%%%%%%% HEADER %%%%%%%%%%%%%%%%%%%%%

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{Arnau Abella Gassol}
\lhead{Randomized Algorithms}
\rfoot{Page \thepage}

%%%%%%%%%%%%%%%% TITLE %%%%%%%%%%%%%%%%%%%%%

\title{%
  Randomized Algorithms\\
  \large{First Assignment}
}
\author{%
  Arnau Abella \\
  \large{Universitat Polit\`ecnica de Catalunya}
}
\date{\today}

%%%%%%%%%%%%%%%% DOCUMENT %%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

%%%%%%% Exercise 1

\section*{Exercise 1}%
\label{sec:exercise_1}

\begin{enumerate}[label=( \alph*)]
  \item Prove that for each of the following hands, the probability of having the hand is the given one:
    \begin{enumerate}[label=\textbullet]
      \item Having \textit{four of a kind} (four cards of the same value, the other one does not matter). Prob. = 0.000240096

        For example (K,K,K,K,*). The order does not matter. We pick a card over the 13 possible ranks. Then, there is only one combination to pick three cards of the same value. The last card can be chosen arbitrary from the remaining 48 cards of the deck. The resulting probability is:

        \begin{equation}
          \frac{13 \cdot 1 \cdot 48}{\binom{52}{5}} = 0.000240096
        \end{equation}

      \item Having \textit{flush} (five cards of the same suit, not consecutive values). Prob. =0.0019879

        There are 4 possible suits and for each suit we have to choose 5 different cards $\binom{13}{5}$. The resulting probability is:

        \begin{equation}
          \frac{4 \binom{13}{5}}{\binom{52}{5}} = 0.0019879
        \end{equation}

      \item Having \textit{straight flush}  (five cards of the same suit with consecutive values). Prob. = 0.0000153908

        The only possible draws for each suit ($4$ in total) are \{A,K,J,Q,10\}, \{K,J,Q,10,9\}, \{J,Q,10,9,8\} , \ldots, \{5,4,3,2,A\}. The resulting probability is:

        \begin{equation}
          \frac{4 \cdot 10}{\binom{52}{5}} = 0.0000153908
        \end{equation}

    \end{enumerate}
  \item Suppose you are playing with 3 other players, and you have a \textit{four of a kind} . What is the probability one of the other players has a better hand (i.e. a straight flush).

    The probability that one the other players do not have a straight flush is $(1 - \frac{40}{\binom{52}{5}})$. The probability that none of them have a straight flush is $(1 - \frac{40}{\binom{52}{5}})^3$. And the probability that at least one of them has a straight flush is $1 - (1 - \frac{40}{\binom{52}{5}})^3$.
\end{enumerate}


%%%%%%% Exercise 2

\section*{Exercise 2}%
\label{sec:exercise_2}

\begin{enumerate}[label=(\alph*)]
  \item This algorithm is one-side, it may output match when there is no match. Prove the $Pr[\textit{output match, when no match}] \leq 1/c$, for suitable $c > 0$.

    \begin{theorem}
      There is a constant $c > 0$ such that, with probability $\leq \frac{1}{c}$, the \textit{Karp-Rabin algorithm} reports no false positives.
    \end{theorem}

    We need two basic facts from number theory to prove this.

    \begin{lemma}\label{lemma:1}
      Any positive integer $X$ has at most $\log_{2}X$ \textit{distinct prime divisors}.
    \end{lemma}

    The second fact is the famous Prime Number Theorem.

    \begin{lemma}\label{lemma:2}
      Let $\pi(Q)$ be the number of primes in $\{2, \ldots, Q\}$. There exists a constant $d > 0$, independent of $Q$, such that for any integer $Q \geq 2, \pi(Q) \geq \frac{d Q}{\ln Q}$.
    \end{lemma}

    The first lemma can be proven using the Fundamental Theorem of Arithmetic.
    Proving the second lemma is out of the scope of this homework.


    \begin{proof}

      Define $Q = \{q : T(j) \neq S\}$ to be the set set of shifts for which there is no match.

      Define the number

      \begin{equation}\label{eq:4}
        X = \prod_{q \in Q} |D(T(j)) - D(S)|
      \end{equation}

      $X$ is a positive integer. Since $|Q| \leq n - m$ and $|D(T(j)) - D(S)| \leq 2^{m}$, we have $X \leq 2^{m(n - m)} \leq 2^{mn}$. By Lemma \ref{lemma:1}, $X$ has \textit{at most} $mn$ prime divisors.

        Notice that we have a false match exactly when there is a shift $q \in Q$ for which $\phi(T(j)) = \phi(S)$, which happens exactly when $p$ divides $|D(T(j)) - D(S)|$. Therefore, if there is any false match, then $p$ would divide $X$. Hence,

        \begin{align*}
          Pr[output match, when no match]& \\
          \leq Pr[p divides X] &= \frac{\#\{prime divisors of X\}}{\pi(k)} \\
                            &\leq  \frac{mn\ln(cmn\ln(mn))}{dcmn\ln(mn)} \\
                            &= \frac{1}{dc} + \frac{\ln(c)}{dc\ln(mn)} + \frac{\ln\ln(m n)}{dc\ln(mn)}
        \end{align*}

        Given a large enough c the right hand side can be made less than any fixed constant by basic calculus.

    \end{proof}


  \item  Prove that the algorithm can be implemented in $\mathcal{O}(n + m)$ steps.

    \begin{itemize}
        \item Finding all primes up to $k$ can be done in $\mathcal{O}(k)$ using the \textit{the sieve of Atkin}. The prime values could be precomputed.
        \item Computing the fingerprint $\phi(x) = x \mod p$ can be done in constant time assuming p is $O(log n)$ bites long. Then, computing $D(S)$ can be done in $m$ steps. Finally, computing $\phi(D(S))$ can be done in $O(m)$ steps.
        \item The for loop does $n - m + 1$ iterations and at each iteration it does constant number of operations.

        \begin{itemize}
          \item Computing $(D(T(j)))$ can be done in $O(m)$. The obvious total cost is $O(nm)$ but we can compute $\phi(D(T(j)))$ in constant time. Notice $\phi(D(T(j+1)))$ and $\phi(D(T(j)))$ only differ from the first and last term.

            So we can compute ${D(T(j+1)) = 2(D(T(j)) - 2^{m-1}x_{j}) + x_{j + 1}}$ and then compute the fingerprint in constant time.
        \end{itemize}

        The running time of the loop is at most $O(n)$.
    \end{itemize}

    The total number of steps of the \textit{Karp-Rabin algorithm} is $\mathcal{O}(n + m)$.

\end{enumerate}

%%%%%%% Exercise 3

\section*{Exercise 3}%
\label{sec:exercise_3}

\begin{algorithm}[H]
  \SetAlgoNoLine
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \Input{$G = (V, E)$ and $k$ the total number of colors}
  \Output{$G' = (C, V, E)$ where $c_{i} \in C$ is the color assigned to vertex $v_{i} \in V$ and $|C| = |V|$ and $c \in \{1, \ldots, k\}$}
  \For{$u \in V$}{
    \For{$ v \in \{v | edge(u,v) \in E \}$}{
      \uIf{vertex $v$ has no color assigned yet}{
        Pick u.a.r a color from $\{1, \ldots, k\}$ and assign it to vertex $v$
      }
    }
  }
  \caption{Randomized k-COL}                                   
  \label{algo:k-col}
\end{algorithm}

It is easy to see that the proposed algorithm \ref{algo:k-col} computes a valid $k$-coloring assignment in polynomial time.
                                                                                  
Now, let's have a look at the quality of this assignment. Let $X_{uv}$ be the bernoulli random variable that takes 1 when the edge $(u,v)$ is properly colored, and 0 otherwise. Notice that the edge $(u,v)$ is properly colored when the vertex $u$ has a different color from the vertex $v$. Hence,

\begin{equation*}
  E[X_{uv}] = Pr[X_{uv} = 1] = Pr[c(u) \neq c(v)] = 1 - \frac{k}{k^{2}}
\end{equation*}

Let $X$ be the properly colored edges in a graph $G = (E, V)$ of degree $d$ such that $X = \sum_{u \in V}\sum_{v \neq u, (u,v) \in E} X_{uv}$. Then, the expected total number of properly colored edges in a graph satisfies

\begin{align*}
  E[X] &= E[\sum_{u \in V}\sum_{v \neq u, (u,v) \in E} X_{uv}] \\
       &= \sum_{u \in V}\sum_{v \neq u, (u,v) \in E} E[X_{uv}] \\
       &= \sum_{u \in V}\sum_{v \neq u, (u,v) \in E} 1 - \frac{k}{k^{2}} \\
       &\ge  1 - \frac{k}{k^{2}}
\end{align*}

In the case of $3$-coloring, the expected number of properly colored edges is $\ge 1 - \frac{3}{3^{2}} = \frac{2}{3}$.

%%%%%%% Exercise 4

\section*{Exercise 4}%
\label{sec:exercise_4}

Let's analyze the randomized algorithm first and then the deterministic algorithm. Let $X$ be the number of open boxes before getting the winning box. Let $X_{i}$ be the the random variable that takes on the value 1 if the $i$th box is the winning box, and 0 otherwise. Then, the total number of boxes before getting the prize is

\begin{equation*}
  X = \sum_{i-1}^{n}X_{i}
\end{equation*}

and

\begin{align*}
  E[X] &= E[\sum_{i-1}^{n}X_{i}] \\
       &= \sum_{i-1}^{n}E[X_{i}]
\end{align*}

by the linearity of expectations.

Since $X_{i}$ is a bernoulli random variable, $E[X_{i}]$ is equal to the probability that $X_{i}$ is $1$.
Since the boxes are picked uniformly at random from the remaining $n - i$ not opened boxes. the probability of $X_{i} = 1$ is $\frac{1}{n-i+1}$. Finally, the expected number of opened boxes before getting the prize is

\begin{align*}
  E[X] &= E[\sum_{i-1}^{n}X_{i}] \\
       &= \sum_{i-1}^{n}E[X_{i}] \\
       &= \sum_{i-1}^{n} \frac{1}{n-i+1} \\
       &= H_{n}
\end{align*}

Recalling that the harmonic number $H_{n}$ satisfies $H_{n} = \ln n + \theta(1)$, we have $E[X] = \ln n + \theta(1)$.

Next, we consider the deterministic algorithm where the input is given at random with probability $\frac{1}{2}$. The algorithm is essentially the same as the randomized version as the box opened at the iteration $i$th is determined by the \textit{random choice} of the sequence of boxes.

%%%%%%%%%%%%%%%% BIBLIOGRAPHY %%%%%%%%%%%%%%%%%%%%%

% \bibliographystyle{unsrt} % abbrv, aplha, plain, abstract, apa, unsrt,
% \bibliography{refs}

\end{document}
